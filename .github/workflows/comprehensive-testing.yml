name: Comprehensive Testing Pipeline
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run full test suite daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'
  DATABASE_URL: ${{ secrets.TEST_DATABASE_URL }}
  NEXT_PUBLIC_ENV: test

  # AI Testing
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}

  # Payment Testing
  RAZORPAY_KEY_ID: ${{ secrets.RAZORPAY_KEY_ID_TEST }}
  RAZORPAY_KEY_SECRET: ${{ secrets.RAZORPAY_KEY_SECRET_TEST }}

  # Performance Baselines
  PERF_BASELINE_PAGE_LOAD: 3000
  PERF_BASELINE_API: 500
  PERF_BASELINE_SEARCH: 300
  PERF_BASELINE_PAYMENT: 1000

jobs:
  # Job 1: Setup and Validation
  setup:
    name: Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      test-strategy: ${{ steps.strategy.outputs.strategy }}
      skip-tests: ${{ steps.changes.outputs.skip-tests }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Detect changes
        id: changes
        uses: dorny/paths-filter@v2
        with:
          filters: |
            src:
              - 'src/**'
            tests:
              - 'tests/**'
              - '__tests__/**'
            config:
              - '*.config.*'
              - 'package*.json'
            docs:
              - '*.md'
              - 'docs/**'

      - name: Determine test strategy
        id: strategy
        run: |
          if [[ "${{ steps.changes.outputs.src }}" == "true" || "${{ steps.changes.outputs.tests }}" == "true" ]]; then
            echo "strategy=full" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.changes.outputs.config }}" == "true" ]]; then
            echo "strategy=integration" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.changes.outputs.docs }}" == "true" ]]; then
            echo "strategy=docs" >> $GITHUB_OUTPUT
          else
            echo "strategy=minimal" >> $GITHUB_OUTPUT
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Validate project structure
        run: |
          echo "Validating project structure..."
          test -f "package.json" || exit 1
          test -f "next.config.js" || exit 1
          test -f "tailwind.config.js" || exit 1
          test -d "src" || exit 1
          test -d "tests" || exit 1
          echo "✅ Project structure validated"

  # Job 2: Code Quality & Linting
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-strategy != 'docs'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Type checking
        run: npm run type-check

      - name: Linting
        run: npm run lint

      - name: Code formatting check
        run: npx prettier --check .

      - name: Security audit
        run: npm audit --audit-level=high

      - name: Dependency vulnerability scan
        run: npx better-npm-audit audit

  # Job 3: Unit Testing
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy != 'docs'
    strategy:
      matrix:
        test-group: [components, utils, api, ai-services]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test database
        run: |
          # Setup test database for API tests
          npm run db:test:setup || echo "Database setup skipped"

      - name: Run unit tests - ${{ matrix.test-group }}
        run: |
          case "${{ matrix.test-group }}" in
            "components")
              npm run test -- --testPathPattern="components" --coverage --coverageDirectory=coverage/components
              ;;
            "utils")
              npm run test -- --testPathPattern="utils|lib" --coverage --coverageDirectory=coverage/utils
              ;;
            "api")
              npm run test -- --testPathPattern="api" --coverage --coverageDirectory=coverage/api
              ;;
            "ai-services")
              npm run test -- --testPathPattern="ai" --coverage --coverageDirectory=coverage/ai
              ;;
          esac

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/${{ matrix.test-group }}/lcov.info
          flags: unit-tests-${{ matrix.test-group }}
          name: ${{ matrix.test-group }}-coverage

  # Job 4: Integration Testing
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full' || needs.setup.outputs.test-strategy == 'integration'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: cerebrum_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Database migration
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/cerebrum_test
        run: |
          npm run db:migrate || echo "Migration skipped"
          npm run db:seed:test || echo "Seeding skipped"

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30  # Wait for app to start

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/cerebrum_test
        run: npm run test:integration

      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: test-results/integration/

  # Job 5: AI Content Quality Testing
  ai-content-testing:
    name: AI Content Quality
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run AI content quality tests
        env:
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ env.ANTHROPIC_API_KEY }}
        run: npm run test -- --testPathPattern="ai.*quality" --verbose

      - name: Generate AI testing report
        run: |
          echo "# AI Content Quality Report" > ai-report.md
          echo "Generated at: $(date)" >> ai-report.md
          echo "" >> ai-report.md
          npm run test -- --testPathPattern="ai.*quality" --json > ai-test-results.json
          node scripts/generate-ai-report.js >> ai-report.md

      - name: Upload AI testing report
        uses: actions/upload-artifact@v3
        with:
          name: ai-content-quality-report
          path: |
            ai-report.md
            ai-test-results.json

  # Job 6: End-to-End Testing
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality, unit-tests]
    if: needs.setup.outputs.test-strategy == 'full'
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
        test-suite: [critical-path, enrollment-flow, payment-flow]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install ${{ matrix.browser }} --with-deps

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30

      - name: Run E2E tests - ${{ matrix.test-suite }}
        run: |
          case "${{ matrix.test-suite }}" in
            "critical-path")
              npx playwright test --project=${{ matrix.browser }} tests/e2e/critical-path/
              ;;
            "enrollment-flow")
              npx playwright test --project=${{ matrix.browser }} tests/e2e/enrollment/
              ;;
            "payment-flow")
              npx playwright test --project=${{ matrix.browser }} tests/e2e/payment/
              ;;
          esac

      - name: Upload E2E test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-results-${{ matrix.browser }}-${{ matrix.test-suite }}
          path: |
            test-results/
            playwright-report/

  # Job 7: Performance Testing
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30

      - name: Run performance tests
        run: npx playwright test --project=performance tests/performance/

      - name: Run load tests
        run: |
          # Install Artillery for load testing
          npm install -g artillery
          artillery run tests/load/basic-load-test.yml

      - name: Generate performance report
        run: |
          echo "# Performance Test Report" > performance-report.md
          echo "Generated at: $(date)" >> performance-report.md
          echo "" >> performance-report.md
          cat test-results/performance-metrics.json | jq . >> performance-report.md

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: |
            performance-report.md
            test-results/performance-metrics.json

  # Job 8: Security Testing
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30

      - name: Run security tests
        run: npx playwright test --project=security tests/security/

      - name: Run OWASP ZAP security scan
        uses: zaproxy/action-full-scan@v0.4.0
        with:
          target: 'http://localhost:3000'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a'

      - name: Upload security scan results
        uses: actions/upload-artifact@v3
        with:
          name: security-scan-results
          path: |
            report_html.html
            report_json.json

  # Job 9: Mobile Testing
  mobile-tests:
    name: Mobile Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30

      - name: Run mobile tests
        run: npx playwright test --project="Mobile Chrome" tests/e2e/mobile/

      - name: Upload mobile test results
        uses: actions/upload-artifact@v3
        with:
          name: mobile-test-results
          path: test-results/mobile/

  # Job 10: Accessibility Testing
  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: needs.setup.outputs.test-strategy == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps

      - name: Start application
        run: |
          npm run build
          npm run start &
          sleep 30

      - name: Run accessibility tests
        run: npx playwright test --project=accessibility tests/accessibility/

      - name: Generate accessibility report
        run: |
          echo "# Accessibility Test Report" > accessibility-report.md
          echo "Generated at: $(date)" >> accessibility-report.md
          echo "" >> accessibility-report.md
          cat test-results/accessibility-report.json | jq . >> accessibility-report.md

      - name: Upload accessibility results
        uses: actions/upload-artifact@v3
        with:
          name: accessibility-test-results
          path: |
            accessibility-report.md
            test-results/accessibility-report.json

  # Job 11: Generate Final Report
  generate-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [
      unit-tests,
      integration-tests,
      ai-content-testing,
      e2e-tests,
      performance-tests,
      security-tests,
      mobile-tests,
      accessibility-tests
    ]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test artifacts
        uses: actions/download-artifact@v3

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Generate comprehensive test report
        run: |
          node scripts/generate-test-report.js > comprehensive-test-report.md

      - name: Upload comprehensive report
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-report
          path: comprehensive-test-report.md

      - name: Comment on PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('comprehensive-test-report.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 🧪 Comprehensive Test Results\n\n${report}`
            });

  # Job 12: Deploy to Staging (if all tests pass)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [generate-report]
    if: github.ref == 'refs/heads/develop' && success()
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Vercel Staging
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          scope: ${{ secrets.VERCEL_ORG_ID }}

      - name: Run smoke tests on staging
        run: |
          sleep 30  # Wait for deployment
          curl -f https://staging.cerebrumbiologyacademy.com/api/health || exit 1

  # Job 13: Notification
  notify:
    name: Notify Team
    runs-on: ubuntu-latest
    needs: [generate-report]
    if: always()
    steps:
      - name: Notify on success
        if: success()
        run: |
          echo "✅ All tests passed successfully!"
          # Add Slack/Discord notification here

      - name: Notify on failure
        if: failure()
        run: |
          echo "❌ Some tests failed. Check the reports."
          # Add Slack/Discord notification here